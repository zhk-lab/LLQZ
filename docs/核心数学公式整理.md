

# 实验一：动态检索策略有效性验证

A. 混合检索加权公式 
我们不仅计算向量相似度，还结合关键词匹配度。实验代码中实现以下加权逻辑：

$$S_{hybrid}(q, d) = \alpha \cdot \mathcal{N}(S_{dense}(q, d)) + (1 - \alpha) \cdot \mathcal{N}(S_{sparse}(q, d))$$

变量说明：

$\alpha$：平衡因子。实验中需固定 $\alpha=0.7$（或进行敏感性测试）。

$\mathcal{N}$：归一化函数。代码中需对 BM25 分数和 Cosine 分数分别做 Min-Max Normalization，映射到 $[0,1]$ 区间。

$S_{dense}$：Embedding 余弦相似度。

$S_{sparse}$：BM25 得分。

B. 重排序打分模型 
在召回 Top-K 后，利用 BERT 的全注意力机制进行精排：

$$S_{rerank}(q, d) = \sigma \left( \mathbf{W} \cdot \text{BERT}_{\text{CLS}}([CLS] ; q ; [SEP] ; d) \right)$$

操作含义： 调用 Rerank 模型接口，输出一个 $0 \sim 1$ 的概率值，作为最终排序依据。

# 实验二：基于语义熵的幻觉检测 


A. 双向蕴含判定 
判断两个回答 $s_i$ 和 $s_j$ 是否意思一样，代码需调用 NLI 模型判断：

$$E(s_i, s_j) \iff (s_i \Rightarrow s_j) \land (s_j \Rightarrow s_i)$$

B. 语义熵计算 
这是本实验的最终产出指标。代码需先聚类，再算熵：

$$SE(x) = - \sum_{k=1}^{K} p(c_k | x) \log p(c_k | x)$$

变量说明：

$p(c_k|x)$：第 $k$ 个语义类（意思相同的一组回答）的概率之和。

$K$：聚类后的总类别数。


# 实验三：自反思机制修正能力


A. 综合评分函数
模型在生成时，不是随机选择，而是选择“得分最高”的片段。代码逻辑体现这个加权过程：

$$Score(y_t) = P(y_t) + \sum_{k \in \{rel, sup, use\}} w_k \cdot P(r_k = \text{Positive})$$

变量说明：

$P(y_t)$：生成这段文字原本的概率。

$r_{sup}$：支持度令牌 。这是实验重点。

$w_{sup}$：权重。实验中我们强调事实性，设定 $w_{sup}=2.0$（即如果模型觉得自己这句话有文档支持，得分会大大增加）。

