# 实验三结果分析报告（BioASQ，Self-RAG 自反思纠错机制）

> 本报告面向论文写作：总结实验设定、关键结果、图像解读与结论。  
> 对应产物：`runs/exp3_v2/metrics_summary.json`、`plots/exp3_quality_metrics_v2.png`、`plots/exp3_correction_gain_v2.png`。

---

## 1. 实验目的与核心问题

实验三验证 Self-RAG 的核心主张：在给定同一检索证据的条件下，通过“候选生成 + critic 反思评估 + 打分选择”，能否：

1. 提升回答质量（FactScore proxy / Correct Rate）与引用质量（Citation Precision）；
2. 在纠错方面体现净收益：更多 **Wrong→Correct**（修正）且更少 **Correct→Wrong**（引入新错）；
3. 该净收益是否具有统计显著性（配对检验）。

本实验对比三套系统输出：

- `naive_rag`：直接基于证据生成答案（对照组）
- `self_rag_wo_weight`：Self-RAG ablation（去除反思权重）
- `self_rag_full`：Self-RAG 完整版（含反思权重与保守选择规则）

---

## 2. 数据与实现设置（v2）

### 2.1 输入与题目规模

- 检索来源：`runs/exp1/hybrid_rerank/predictions.jsonl`（不重跑实验一，直接复用检索结果）
- 题目数：`max_questions = 200`

### 2.2 Self-RAG 生成与选择（关键超参）

本轮 v2 的重点是“放大候选差异并降低引入新错”，因此采用：

- 证据条数：`top_n = 5`
- 候选数：`num_candidates = 8`
- 反思打分权重：`theta = 1.2`，`w_rel = 1.0`，`w_sup = 3.0`，`w_use = 1.0`
- 候选采样：`candidate_temperature = 0.9`，`candidate_top_p = 0.95`
- **保守门控（仅对 full 生效）**：
  - 安全阈值：`min_rel_prob = 0.55`，`min_sup_prob = 0.65`，`min_use_prob = 0.50`
  - 引用加分：`citation_bonus = 0.20`
  - 不安全惩罚：`unsafe_penalty = 0.55`
  - 若无候选通过门控，则按 `sup_prob -> rel_prob -> score` 的顺序保守回退选择

> 注：critic 模型与生成模型均使用 `qwen/qwen3-4b`（本地 `base_url = http://127.0.0.1:1234/v1`）。

### 2.3 评估指标与“正确”判定

评估脚本：`scripts/exp3_evaluate_and_plot.py`，主要指标：

- **FactScore proxy (token-F1)**：预测与 `ideal_answer` 的 token-F1 平均值
- **Citation Precision**：引用 doc_id 命中 `gold_docs` 的比例（均值）
- **Correct Rate**：以 `token-F1 >= correctness_threshold` 判定正确，本轮 `correctness_threshold = 0.20`
- **Correction Gain**：
  - fix：naive 错 → other 对
  - introduce：naive 对 → other 错
  - `paired_sign_pvalue`：对 discordant（fix+introduce）样本做配对二项检验（two-sided）

---

## 3. 主要结果（200 题，threshold=0.20）

来自：`runs/exp3_v2/metrics_summary.json`

### 3.1 质量指标总览

| System | FactScore proxy (F1) | Citation Precision | Correct Rate |
|---|---:|---:|---:|
| naive_rag | 0.2151 | 0.8045 | 0.535 |
| self_rag_wo_weight | 0.2256 | 0.8095 | 0.605 |
| **self_rag_full** | **0.2333** | **0.8452** | **0.620** |

结论：

- `self_rag_full` 在三项质量指标上均优于 `naive_rag`；
- `correct_rate` 从 `0.535` 提升至 `0.620`，绝对提升 `+0.085`（8.5 个百分点）。

### 3.2 纠错收益与显著性

`full_vs_naive`：

- `n_fix = 26`，`n_introduce = 9`，`n_discordant = 35`
- `delta_correct_rate = +0.085`
- `paired_sign_pvalue = 0.00599`（< 0.01）

`wo_weight_vs_naive`：

- `n_fix = 20`，`n_introduce = 6`，`n_discordant = 26`
- `delta_correct_rate = +0.070`
- `paired_sign_pvalue = 0.00936`（< 0.01）

解读：

- 两个 Self-RAG 变体均表现出**统计显著的净纠错收益**（p-value < 0.01）；
- full 版修正更多（fix 更高），但也引入更多新错（introduce 更高），整体净增益仍为正且更强。

---

## 4. 图像结果解读

### 4.1 图 1：三系统质量对比（柱状图）

文件：`plots/exp3_quality_metrics_v2.png`

观察：

- `self_rag_full` 在 FactScore proxy (F1) 与 Citation Precision 上均最高；
- Correct Rate 亦最高，说明“候选+反思选择”不仅改善文本相似度，也提高了在阈值判定下的正确率。

### 4.2 图 2：纠错收益与副作用（堆叠条 + 折线）

文件：`plots/exp3_correction_gain_v2.png`

观察：

- 两个 Self-RAG 变体的 fix（Wrong→Correct）均明显高于 introduce（Correct→Wrong），因此 Δ Correct Rate 为正；
- full 版同时提高 fix 与 introduce，但 fix 的增量更大，净收益更高。

---

## 5. 结论（可直接用于论文）

在 BioASQ 的 200 题评测上，Self-RAG（full）在不重跑检索的前提下，基于候选生成与反思选择实现了稳定净增益：Correct Rate 从 0.535 提升到 0.620（+8.5 个百分点），同时提升 FactScore proxy (F1) 与 Citation Precision。纠错对比中 fix 明显多于 introduce，配对检验 p-value < 0.01，表明增益具有统计显著性。该结果支持 Self-RAG 作为“在相同检索证据下提升回答可靠性”的有效机制。

---

## 6. 局限性与改进方向

- **评价口径偏保守**：Correct Rate 由 token-F1 阈值定义，可能低估同义改写与事实等价带来的真实提升；可补充更语义的 judge（BERTScore/LLM-judge）或人工抽样核验。
- **critic 与生成同模**：critic 仍使用 `qwen3-4b`，存在“自评偏差”与格式不稳定风险；若使用更强/更稳的 judge，introduce 有望进一步下降。
- **上下文长度约束**：当证据文本较长时可能触发 context 超限；可引入 evidence 截断/压缩或自动降级重试策略以提升稳定性。

