# 引言 

## 研究背景与领域痛点

随着以 Transformer 为架构的大语言模型的爆发式发展，生成式人工智能已展现出强大的自然语言理解与推理能力。然而，在将 LLMs 应用于生物医疗、金融风控等高风险垂直领域时，模型固有的**幻觉** 问题,即生成看似流畅但事实错误的回答,成为了限制其落地的最大瓶颈。

当前“人工智能+数据赋能”面临以下三大核心痛点：

参数化知识的滞后性与不可溯源性： 传统的 LLMs 将知识隐式存储在神经网络权重中 [1]。这导致模型无法实时更新知识，且无法提供决策的证据来源，难以满足医疗诊断和金融审计对可解释性的严苛要求。

长尾知识的概率性失效： 在面对非结构化数据（如复杂的临床指南或长篇金融年报）时，LLMs 往往出现 "Lost in the Middle" 现象 [6]，即模型难以捕捉长上下文中间的关键信息，导致信息遗漏或篡改。

盲目检索带来的噪声干扰： 现有的朴素检索增强生成框架缺乏对检索必要性的判断。无论问题是否需要外部知识，系统均强制检索，引入了大量无关噪声，反而降低了模型的推理准确度 [5]。

## 研究意义

本研究紧密围绕“人工智能时代数据赋能应用及研究”这一主题，旨在通过数学建模与算法创新，解决非结构化数据在垂域应用中的可信度与 准确性 问题。

理论意义： 本文引入语义熵 [3] 作为不确定性的数学度量，将语言模型的幻觉检测问题转化为概率分布的统计推断问题，为大模型的“诚实性”提供了严谨的数学描述。

应用价值：

在医疗领域： 构建“自反思智能体”，能够基于权威医学指南对生成的诊断建议进行实时事实核查，降低误诊风险。

在金融领域： 实现对海量上市公司年报的自动化合规审查，通过动态检索技术激活沉睡的文档数据，提升数据要素的利用效率与经济效益。

## 本文创新点

针对上述问题，本文提出了一种基于语义熵不确定性量化与自反思机制的动态 RAG 框架。主要创新点如下：

提出基于语义等价类的聚类算法： 摒弃了传统的基于 Token 概率的不确定性计算，利用双向蕴含关系构建语义等价类，通过计算语义分布的香农熵，更精准地识别语义层面的幻觉风险。

构建检索-生成-批评的闭环概率模型： 借鉴 Self-RAG [5] 与 Reflexion [4] 思想，设计了特殊的反思令牌 (Reflection Tokens)，使模型具备自我评价能力（相关性、支持度、有用性），实现了从“开环生成”到“闭环修正”的范式转变。

设计混合检索与动态重排序策略： 针对“长上下文迷失”问题，融合稀疏检索与稠密检索，并引入 Cross-Encoder 进行重排序，通过数学加权最大化检索结果的信息增益。

# 相关工作 

## 检索增强生成范式的演进

检索增强生成通过结合参数化记忆与非参数化记忆（外部知识库）来增强模型的生成能力。Lewis 等人 [1] 最早提出了 RAG 框架，证明了混合模型在知识密集型任务上显著优于单纯的 Seq2Seq 模型。

根据 Gao 等人 [2] 的综述，RAG 的发展经历了三个阶段：

Naive RAG: 采用“检索-阅读-生成”的简单线性流程，依赖余弦相似度进行文档召回。

Advanced RAG: 引入了预检索和后检索优化。

Modular RAG: 将检索视为一个插件模块，支持迭代检索和递归检索。

然而，现有 RAG 架构大多属于被动式检索，即预先设定检索频次,如每生成 k 个 token 检索一次，缺乏根据任务难度和模型自身状态动态决定是否检索的机制。

## 大模型不确定性量化 

准确估计模型的不确定性是检测幻觉的前提。早期的研究主要关注词元级不确定性，即计算生成序列的平均对数概率（Log-Probability）或困惑度（Perplexity）。

但是，Kuhn 等人 [3] 指出，语言生成的特殊性在于“多词同义”。例如，“Beijing”和“It is Beijing”在字面上不同，但语义相同。直接计算 Token 熵会高估模型的不确定性。因此，该研究提出了语义熵 的概念，即在语义等价类的层面上计算熵值。这一数学工具为本文构建“幻觉触发器”提供了核心理论支撑。

## 自反思与智能体 

为了提升模型的鲁棒性，研究者开始探索让模型具备类似人类的“反思”能力。Shinn 等人提出了 Reflexion 框架 [4]，通过语言强化学习，让智能体将错误反馈转化为自然语言形式的短期记忆，从而在后续尝试中自我修正，无需更新模型权重。

在此基础上，Asai 等人提出了 Self-RAG [5]，通过训练模型生成特殊的反思令牌 （如 [IsREL], [IsSUP]），实现了细粒度的自我批评。

此外，Liu 等人 [6] 的研究揭示了 "Lost in the Middle" 现象，即当相关信息位于长上下文的中间位置时，Transformer 模型的注意力机制往往失效。这一发现表明，单纯增加上下文窗口长度并不能解决问题，必须引入重排序机制来确保关键信息位于生成的局部注意力窗口内。

## 现有方法的不足

综上所述，尽管 RAG 和不确定性研究取得了显著进展，但仍存在以下局限性：

检索与生成的割裂： 大多数 RAG 系统中，检索器与生成器是独立优化的，缺乏联合概率约束。

不确定性利用不足： 现有的语义熵研究多用于事后分析，未将其作为实时控制信号来动态触发检索或截断生成。

计算开销与精度的平衡： 完整的 Self-RAG 需要昂贵的模型微调，而 Reflexion 依赖多轮 API 调用。




* [1] 对应 Lewis (RAG)

* [2] 对应 Gao (Survey)

* [3] 对应 Kuhn (Semantic Uncertainty)

* [4] 对应 Shinn (Reflexion)

* [5] 对应 Asai (Self-RAG)

* [6] 对应 Liu (Lost in the Middle)

